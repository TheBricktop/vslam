In this first lecture we are going to provide a draft of what we are going to do later.
We will look through sketch of the whole system and
we will list things that you will need to learn in order to be able
to understand the code, use it yourself or make it better.

This course is positioned to maximize accessibility aka make it easy to grasp quickly.
If you want steepest possible learning curve, go to ORB-SLAM3 source code and paper and start reading.
If you want more background on this current course

TODO: Why is this an important algorithm ? Why do we need it ?

We are going to make an agent that goes through environment and figures out where it is.

We are going to use simulated environment, but same exact code / principles apply to real life cases.

This code won't try to be production ready - we will prioritize being easy to learn over being fast.

In practice you may need better speed to be able to deploy this thing.
Usually this means that you would need more threads, more processes and c++.

The agent has two cameras.

First, it uses information from two cameras to estimate depth of the points it sees.
The agent remembers this information and call this reference frame "keyframe".
The special thing about the keyframe is that it has a bunch of 3d points attached to it.
This points have estimated (triangulated) depth and

Then, as the agent moves on, it compares the new information from left eye in reference keyframe to information
that the left eye currently sees.

It tries to figure out which elements of the image are the same elements as it has seen before and
based on their movement, it figures out how much it has moved.

As it gets away from the keyframe, the shared elements between the keyframes current left eye image
and past left eye image might get more rare. We have moved on so we see other stuff.
So we need to make a new keyframe
